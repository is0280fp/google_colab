{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "training_spectrogram.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1ijdXNpxuZHp7dm0zBtwiR-ocqDlg6IYg",
      "authorship_tag": "ABX9TyMgHhDYfW4RKZ2Ugk2KaOYI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/is0280fp/google_colab/blob/use_image_as_input/training_spectrogram.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zNwUIy5fsXtu",
        "outputId": "c38196bb-a75c-4709-c2ba-79b1535e747d"
      },
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wx9ajZC-pFYu"
      },
      "source": [
        "# ラベルの読み込み\n",
        "import pickle\n",
        "with open(\"/content/drive/MyDrive/pickle/label_five_class.pickle\", mode=\"rb\") as f:\n",
        "   label = pickle.load(f)\n",
        "f.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VBQp7qm8Z4Jw",
        "outputId": "f2267d4d-0f1b-44a4-f046-f031ef6281a9"
      },
      "source": [
        "# データセット内訳チェック\n",
        "import numpy as np\n",
        "\n",
        "print(np.array(np.where(label == 0)).shape)\n",
        "print(np.array(np.where(label == 1)).shape)\n",
        "print(np.array(np.where(label == 2)).shape)\n",
        "print(np.array(np.where(label == 3)).shape)\n",
        "print(np.array(np.where(label == 4)).shape)\n",
        "\n",
        "# NaNチェック\n",
        "print(np.isnan(label).sum())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 7755)\n",
            "(1, 12748)\n",
            "(1, 19873)\n",
            "(1, 21386)\n",
            "(1, 13970)\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-KPR8cl7-ul",
        "outputId": "49e0f21d-30f3-4840-a627-d2d9a36d51fa"
      },
      "source": [
        "label.shape"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(75732,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdXgcprG6dXD",
        "outputId": "2c7c6e92-27aa-4b97-ca20-a581a8fdf636"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import optimizers, regularizers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, LSTM, InputLayer, Dense, Dropout, Activation, Flatten, concatenate, Conv1D, MaxPooling1D, Input, Reshape, Bidirectional, GlobalAveragePooling2D\n",
        "from keras.models import Model\n",
        "from tensorflow.keras.callbacks import TensorBoard, LearningRateScheduler\n",
        "import time\n",
        "import math\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import keras\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# NAME = \"HC-vs-C-LSTM_2class\"\n",
        "# NAME = \"HC-vs-A-LSTM_2class\"\n",
        "# NAME = \"HC-vs-K-LSTM_2class\"\n",
        "# NAME = \"HC-vs-H-LSTM_2class\"\n",
        "# NAME = \"HC-vs-GDs-LSTM_2class\"\n",
        "# NAME = \"H-vs-K-vs-A-vs-C-LSTM_4class\"\n",
        "#NAME = \"HC-vs-H-vs-K-vs-A-vs-C-LSTM_5class\"\n",
        "# NAME = \"H-vs-K-vs-A-vs-C-CNN_4class\"\n",
        "NAME = \"HC-vs-Patients-CNN_5class\"\n",
        "# NAME = \"HC-vs-GDs-CNN_2class\"\n",
        "# NAME = \"HC-vs-H-CNN_2class\"\n",
        "# NAME = \"HC-vs-K-CNN_2class\"\n",
        "# NAME = \"HC-vs-A-CNN_2class\"\n",
        "# NAME = \"HC-vs-C-CNN_2class\"\n",
        "\n",
        "#-----------------------------------初期設定-------------------------------------------\n",
        "# tensorboardのログ\n",
        "tensorboard = TensorBoard(log_dir=\"logs/{}\".format(NAME))\n",
        "\n",
        "# 学習打ち切り目安\n",
        "early_stopping = EarlyStopping(\n",
        "                        monitor='val_loss',\n",
        "                        min_delta=0.0,\n",
        "                        patience=10,\n",
        "                )\n",
        "\n",
        "# checkpointの設定\n",
        "checkpoint = ModelCheckpoint(\n",
        "                    filepath=\"saved_model/{}\".format(NAME),\n",
        "                    monitor='val_loss',\n",
        "                    save_best_only=True,\n",
        "                    period=1,\n",
        "                )\n",
        "\n",
        "# weightの初期化\n",
        "# initializer = tf.initializers.he_normal()\n",
        "\n",
        "#-----------------------------------学習モデル作成-------------------------------------------\n",
        "\n",
        "\n",
        "#-----------------------------------Optimizer-------------------------------------------\n",
        "# Optimizer: 多クラス分類+Adam\n",
        "# model.compile(loss='sparse_categorical_crossentropy', \n",
        "#               optimizer= optimizers.Adam(lr=0.002, beta_1= 0.9, beta_2= 0.999),\n",
        "#               metrics=['accuracy'],\n",
        "#               )\n",
        "\n",
        "# Optimizer: 多クラス分類+SGD\n",
        "# model.compile(loss='sparse_categorical_crossentropy',\n",
        "#               optimizer= optimizers.SGD(lr=5e-2, decay=1e-2),\n",
        "#               metrics=['accuracy'],\n",
        "#               )\n",
        "\n",
        "# Optimizer: 2クラス分類\n",
        "# model.compile(loss='binary_crossentropy',\n",
        "#               optimizer= optimizers.SGD(lr=5e-3),\n",
        "#               metrics=['accuracy'],\n",
        "#               )\n",
        "\n",
        "#-----------------------------------summer出力-------------------------------------------\n",
        "# model.summary()\n",
        "\n",
        "#-----------------------------------学習-------------------------------------------\n",
        "# model.fit(X, train_label,\n",
        "#           batch_size=5,\n",
        "#           epochs=1000,\n",
        "#           validation_split=0.2,\n",
        "#           callbacks=[tensorboard])\n",
        "\n",
        "# training parameters = kernel_size * (1Dだったらここは1, 2Dだったらここはkernel_size) * output_channels + num_bias\n",
        "# 216 = 8 * 1 * 24 + 24"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQdc-9W5DVLn"
      },
      "source": [
        "# 学習モデル構成\n",
        "def lenet(INPUT_SHAPE, num_classes):\n",
        "    \"\"\"\n",
        "    http://tecmemo.wpblog.jp/wp-content/uploads/2017/03/dl_lenet-01.png この表を参考に一部活性化関数を変更してLenetを定義\n",
        "    \"\"\"\n",
        "    initializer = tf.initializers.he_normal()\n",
        "    model = Sequential()\n",
        "    # フィルターを6枚用意, 小窓のサイズ5×5, paddingによって入力と出力の画像サイズは同じ\n",
        "    # from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
        "    model.add(Conv2D(\n",
        "        64, kernel_size=3, padding=\"same\",\n",
        "        input_shape=INPUT_SHAPE, activation=\"relu\",\n",
        "        kernel_initializer=initializer\n",
        "    ))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "    model.add(Conv2D(64, kernel_size=3, strides=1, padding=\"same\",\n",
        "                     activation=\"relu\", kernel_initializer=initializer))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\",\n",
        "                     activation=\"relu\", kernel_initializer=initializer))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\",\n",
        "                     activation=\"relu\", kernel_initializer=initializer))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "    model.add(Conv2D(128, kernel_size=3, strides=1, padding=\"same\",\n",
        "                     activation=\"relu\", kernel_initializer=initializer))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\",\n",
        "                     activation=\"relu\", kernel_initializer=initializer))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "    model.add(Conv2D(256, kernel_size=3, strides=1, padding=\"same\",\n",
        "                     activation=\"relu\", kernel_initializer=initializer))\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), strides=2))\n",
        "\n",
        "    model.add(Conv2D(512, kernel_size=3, strides=1, padding=\"same\",\n",
        "                     activation=\"relu\", kernel_initializer=initializer))\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    # Flatten()はマトリックスを1次元ベクトルに変換する層\n",
        "    # FCにつなぐために必要\n",
        "    model.add(Dense(num_classes, kernel_initializer=initializer))\n",
        "    model.add(Dropout(0.6))\n",
        "    model.add(Activation(\"softmax\"))\n",
        "    model.summary()\n",
        "    return model"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K9Jgh1RXNzjC"
      },
      "source": [
        "# 入力データの加工\n",
        "\n",
        "def conv_binary(number):\n",
        "  V_left_filename = '/content/spectrogram_data/V_left/{}.png'.format(number)\n",
        "  V_right_filename = '/content/spectrogram_data/V_right/{}.png'.format(number)\n",
        "  V_left_img = Image.open(V_left_filename)\n",
        "  V_right_img = Image.open(V_right_filename)\n",
        "  V_left_img = V_left_img.resize((256, 512))\n",
        "  V_right_img = V_right_img.resize((256, 512))\n",
        "  # 色の変換も簡単ですが、できる色が制限されます。\n",
        "  # print(img.mode) # RGBA\n",
        "  V_left_rgb = np.array(V_left_img.convert('RGB'))\n",
        "  V_right_rgb = np.array(V_right_img.convert('RGB'))\n",
        "  # numpy配列の取得\n",
        "  img_array = np.concatenate([V_left_rgb, V_right_rgb], axis=1)\n",
        "  return img_array"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hdvubAwGfJW"
      },
      "source": [
        "def get_batch(batch_size, X, Y):\n",
        "    \"\"\"\n",
        "    batchを取得する関数\n",
        "    \"\"\"\n",
        "    SIZE = len(X)\n",
        "    # n_batchs\n",
        "    n_batchs = SIZE//batch_size\n",
        "    # for でyield\n",
        "    i = 0\n",
        "    while ((i+batch_size) < SIZE):\n",
        "        # print(\"doing\", i, \"/\", n_batchs)\n",
        "        # Y_batch = Y[(i * n_batchs):(i * n_batchs + batch_size)]\n",
        "        Y_batch = Y[i:(i + batch_size)]\n",
        "        \n",
        "        #あるbatchのfilenameの配列を持っておく\n",
        "        # X_batch_name = X[(i * n_batchs):(i * n_batchs + batch_size)]\n",
        "        X_batch_name = X[i:(i + batch_size)]\n",
        "\n",
        "        # filenameにしたがってバッチのtensorを構築\n",
        "        X_batch = np.array([conv_binary(file) for file in X_batch_name])\n",
        "        \n",
        "        # これで(batch_size, 28, 28, 1)のtrainのテンソルが作られる\n",
        "        i += 1\n",
        "        yield X_batch, Y_batch"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hpw_JfWO86am"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from keras.callbacks import LearningRateScheduler\n",
        "\n",
        "# def step_decay(epoch):\n",
        "#     x = 0.1\n",
        "#     if epoch >= 150: x = 0.01\n",
        "#     if epoch >= 225: x = 0.001\n",
        "#     return x\n",
        "# lr_decay = LearningRateScheduler(step_decay)\n",
        "\n",
        "model = lenet((512, 512, 3), 5)\n",
        "model.compile(loss='sparse_categorical_crossentropy',\n",
        "              optimizer=optimizers.Adam(lr=0.001, beta_1= 0.9, beta_2= 0.999),\n",
        "              metrics=['accuracy'])\n",
        "N_EPOCHS = 1000\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "# acquire the .png name\n",
        "TRAINS = np.array(range(len(label)))\n",
        "y = label\n",
        "# # split test and train\n",
        "# X_train, X_test, Y_train, Y_test = train_test_split(\n",
        "#     TRAINS, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# split test and the others\n",
        "X_train_and_val, X_test, Y_train_and_val, Y_test = train_test_split(\n",
        "    TRAINS, y, test_size=0.1, random_state=42)\n",
        "\n",
        "# split k-folds (その中の一つのfoldがvalidationのためのtestデータとなる)\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "for X_index, Y_index in skf.split(X_train_and_val, Y_train_and_val):\n",
        "    # print(\"train_index:\", train_index, \"val_index:\", val_index)\n",
        "    # print(\"train data\", X_train_and_val[X_index])\n",
        "    # print(\"train label\", Y_train_and_val[X_index])\n",
        "    # print(\"test data\", X_train_and_val[Y_index])\n",
        "    # print(\"test label\", Y_train_and_val[Y_index])\n",
        "\n",
        "    train_data = X_train_and_val[X_index]\n",
        "    train_label = Y_train_and_val[X_index]\n",
        "    test_data = X_train_and_val[Y_index]\n",
        "    test_label = Y_train_and_val[Y_index]\n",
        "\n",
        "    steps_per_epoch=len(X_train_and_val[X_index])//BATCH_SIZE \n",
        "    validation_steps=len(X_train_and_val[Y_index])//BATCH_SIZE \n",
        "\n",
        "training_generator = get_batch(BATCH_SIZE, train_data, train_label)\n",
        "validation_generator = get_batch(BATCH_SIZE, test_data, test_label)\n",
        "\n",
        "# from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
        "model.fit_generator(\n",
        "    generator=training_generator,\n",
        "    validation_data=validation_generator,\n",
        "    steps_per_epoch=steps_per_epoch,\n",
        "    validation_steps=validation_steps,\n",
        "    epochs=N_EPOCHS\n",
        "    # callbacks=[tensorboard]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qqblAWXn9rwD",
        "outputId": "ebad3340-0062-4a84-e709-0a33bd02d666"
      },
      "source": [
        "print(steps_per_epoch)\n",
        "print(len(X_train_and_val[X_index]))\n",
        "print(BATCH_SIZE)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7667\n",
            "61343\n",
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f7xCzsUOMut2",
        "outputId": "4f5c66cb-ed22-49e2-817b-9e43bd8decca"
      },
      "source": [
        "print(X_train_and_val[X_index].shape)\n",
        "print(X_index.shape)\n",
        "print(X_train_and_val[X_index][0])\n",
        "print(X_index[0])\n",
        "TRAINS"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(61343,)\n",
            "(61343,)\n",
            "10137\n",
            "0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([    0,     1,     2, ..., 75729, 75730, 75731])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x1nBpLOa8dpf"
      },
      "source": [
        "# データの読み込み \n",
        "# yesを選ぶように!\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/AP_left.zip\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/AP_right.zip\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/AP_right_69826.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8PcYi1KLxa5G"
      },
      "source": [
        "# データの読み込み\n",
        "# yesを選ぶように!\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/ML_left.zip\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/ML_left_58106.zip\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/ML_right.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UfcILK3fxdA-"
      },
      "source": [
        "# データの読み込み\n",
        "# yesを選ぶように!\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/V_left.zip\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/V_left_48327.zip\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/V_right.zip\n",
        "!unzip /content/drive/MyDrive/zip_spectrogram_data/V_right_34533.zip"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}